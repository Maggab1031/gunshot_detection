{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import multiprocessing\n",
    "import audioop\n",
    "import wave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from gsmmodem.modem import GsmModem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 0\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "audio_volume_threshold = 1000\n",
    "inference_model_confidence_threshold = 0.99\n",
    "phone_numbers_to_message = [\"8163449956\", \"9176202840\", \"7857642331\"]\n",
    "queue_message = \"Gunshot Detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound_data):\n",
    "    # Averages the volume out\n",
    "    sound_normalization_threshold = 16384\n",
    "    times = float(sound_normalization_threshold) / max(abs(i) for i in sound_data)\n",
    "    \n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * times))\n",
    "    return np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "        auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initializer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_one(weights_file):\n",
    "    # 1D Time-Series Model Parameters\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_classes = 2\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_shape = (44100, 1)\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "\n",
    "    output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)\n",
    "\n",
    "    model.load_weights(weights_file)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_two(weights_file):\n",
    "    # Loading 1D Time-Series Model Weights\n",
    "   \n",
    "    #2D Spectrogram Model Parameters\n",
    "    input_shape = (128, 87, 1)\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    filter_size = (3,3)\n",
    "    maxpool_size = (3,3)\n",
    "    activation = \"relu\"\n",
    "    drop_out_rate = 0.1\n",
    "    number_of_classes = 2\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "\n",
    "    # Loading 2D Spectrogram Model\n",
    "    x = layers.Conv2D(16, filter_size, activation=activation, padding=\"same\")(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, filter_size, activation=activation, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, filter_size, activation=activation, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, filter_size, activation=activation, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "    x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation=activation)(x)\n",
    "    x = layers.Dense(1028, activation=activation)(x)\n",
    "    output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    spec_model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    spec_model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)\n",
    "\n",
    "    # Loading 2D Spectrogram Model Weights\n",
    "    spec_model.load_weights(weights_file)\n",
    "    return spec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Process Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing Inference: Currently, there is one audio analysis process running for the duration of the program\n",
    "# The main process adds the microphone data to the audio analysis queue which the audio analysis process then retrieves and analyzes\n",
    "# If the audio analysis process detects the sound of a gunshot, the audio analysis queue will add a \"1\" to the queue, signifying the detection of a gunshot\n",
    "\n",
    "def analyze_microphone_data(audio_rate,save_file=False):\n",
    "    \n",
    "    model = load_model_one(\"./models/gunshot_sound_model.h5\")\n",
    "    \n",
    "    #model = load_model_two(\"./models/gunshot_sound_model_spectrograph_model.h5\")\n",
    "\n",
    "    # An iterator variable for counting the number of gunshot sounds detected\n",
    "    gunshot_sound_counter = 1\n",
    "    \n",
    "    # The audio analysis process will run indefinitely\n",
    "    while True:\n",
    "        # Waits to continue until something is in the queue\n",
    "        microphone_data = audio_analysis_queue.get()\n",
    "        # Performs post-processing on live audio samples\n",
    "        modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "        modified_microphone_data = normalize(modified_microphone_data)\n",
    "        modified_microphone_data = modified_microphone_data[:44100]\n",
    "        modified_microphone_data = modified_microphone_data.reshape(-1, 44100, 1)\n",
    "        # Passes a given audio sample into the model for prediction\n",
    "        probabilities = model.predict(modified_microphone_data)\n",
    "        logger_message = \"Probabilities derived by the model: \" + str(probabilities)\n",
    "        logger.debug(logger_message)\n",
    "        logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])\n",
    "        if (probabilities[0][1] >= inference_model_confidence_threshold):\n",
    "            # Sends out an SMS alert\n",
    "            sms_alert_queue.put(queue_message)\n",
    "            \n",
    "            if save_file:\n",
    "                # Saves the original microphone data sample as a WAV file\n",
    "                microphone_data = pack('<' + ('h' * len(microphone_data)), *microphone_data)\n",
    "                wave_file = wave.open(\"./recordings/Gunshot Sound Sample #\" + str(gunshot_sound_counter) + \".wav\", \"wb\")\n",
    "                wave_file.setnchannels(audio_channels)\n",
    "                wave_file.setsampwidth(2)\n",
    "                wave_file.setframerate(audio_rate)\n",
    "                wave_file.writeframes(microphone_data)\n",
    "                wave_file.close()\n",
    "\n",
    "                # Saves the modified microphone data sample as a WAV file\n",
    "                modified_microphone_data = modified_microphone_data.reshape(44100)\n",
    "                modified_microphone_data = pack('<' + ('h' * len(modified_microphone_data)), *modified_microphone_data)\n",
    "                wave_file = wave.open(\"./recordings/Modified Gunshot Sound Sample #\" + str(gunshot_sound_counter) + \".wav\", \"wb\")\n",
    "                wave_file.setnchannels(audio_channels)\n",
    "                wave_file.setsampwidth(2)\n",
    "                wave_file.setframerate(22050)\n",
    "                wave_file.writeframes(modified_microphone_data)\n",
    "                wave_file.close()\n",
    "\n",
    "                # Increments the counter for gunshot sound file names\n",
    "                gunshot_sound_counter += 1\n",
    "            \n",
    "def send_sms_alert(phone_numbers_to_message,message_mode=False):\n",
    "    \n",
    "    message = \"(Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "    \n",
    "    if message_mode:\n",
    "        # Configuring the Modem Connection if message_mode is True\n",
    "        modem_port = '/dev/ttyUSB0'\n",
    "        modem_baudrate = 115200\n",
    "        modem_sim_pin = None  # SIM card PIN (if any)\n",
    "        # Establishing a Connection to the SMS Modem\n",
    "        logger.debug(\"Initializing connection to modem...\")\n",
    "        modem = GsmModem(modem_port, modem_baudrate)\n",
    "        modem.smsTextMode = False\n",
    "        modem.connect(modem_sim_pin)\n",
    "    \n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == queue_message:\n",
    "            logger.debug(message)\n",
    "            if message_mode:\n",
    "                try:\n",
    "                    # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
    "                    modem.waitForNetworkCoverage(timeout=86400)\n",
    "                    for number in phone_numbers_to_message:\n",
    "                        modem.sendSms(number, message)\n",
    "                    logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "                except:\n",
    "                    logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                    pass\n",
    "                finally:\n",
    "                    logger.debug(\" ** Finished evaluating an audio sample with the model ** \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('output.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the Microphone Audio Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "    \n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True,\n",
    "                 output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-17-0d689a945633>\", line 20, in analyze_microphone_data\n",
      "    modified_microphone_data = normalize(modified_microphone_data)\n",
      "  File \"<ipython-input-13-3ca404058e42>\", line 4, in normalize\n",
      "    times = float(sound_normalization_threshold) / max(abs(i) for i in sound_data)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-13-3ca404058e42>\", line 4, in <genexpr>\n",
      "    times = float(sound_normalization_threshold) / max(abs(i) for i in sound_data)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-17-0d689a945633>\", line 70, in send_sms_alert\n",
      "    sms_alert_status = sms_alert_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-94f700d95314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Loops through the stream and appends audio chunks to the frame array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_rate\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maudio_frames_per_buffer\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maudio_sample_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msound_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_frames_per_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'big'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0msound_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteswap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.debug(\"--- Listening to Audio Stream ---\")\n",
    "\n",
    "audio_analysis_process = multiprocessing.Process(target = analyze_microphone_data, args = (audio_rate,False,))\n",
    "sms_alert_process = multiprocessing.Process(target = send_sms_alert, args = (phone_numbers_to_message,False,))\n",
    "audio_analysis_queue = multiprocessing.Queue()\n",
    "sms_alert_queue = multiprocessing.Queue()\n",
    "audio_analysis_process.start()\n",
    "sms_alert_process.start()\n",
    "\n",
    "while True:\n",
    "    sound_data = array('h')\n",
    "    \n",
    "    # Loops through the stream and appends audio chunks to the frame array\n",
    "    for i in range(0, int(audio_rate / audio_frames_per_buffer * audio_sample_duration)):\n",
    "        sound_buffer = array('h', stream.read(audio_frames_per_buffer, exception_on_overflow = False))\n",
    "        if byteorder == 'big':\n",
    "            sound_buffer.byteswap()\n",
    "        sound_data.extend(sound_buffer)\n",
    "    logger_message = \"The maximum frequency value for a given two-second audio sample: \" + str(max(sound_data))\n",
    "    logger.debug(logger_message)\n",
    "    \n",
    "    # If a sample meets a certain threshold, a new batch of microphone data is placed on the queue\n",
    "    if max(sound_data) >= audio_volume_threshold:\n",
    "        audio_analysis_queue.put(np.array(sound_data))\n",
    "        \n",
    "    # Closes all finished processes   \n",
    "    multiprocessing.active_children()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
