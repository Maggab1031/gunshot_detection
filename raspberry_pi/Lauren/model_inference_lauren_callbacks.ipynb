{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/core/audio.py:37: UserWarning: Could not import scikits.samplerate. Falling back to scipy.signal\n",
      "  warnings.warn('Could not import scikits.samplerate. '\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/display.py:32: MatplotlibDeprecationWarning: \n",
      "The examples.directory rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2. In the future, examples will be found relative to the 'datapath' directory.\n",
      "  mpl.rcParams.update(**_matplotlibrc)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The examples.directory rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2. In the future, examples will be found relative to the 'datapath' directory.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n"
     ]
    }
   ],
   "source": [
    "#uses threads (instead of processes) and the callback version of pyaudio instead of blocking\n",
    "#analyzes, sends texts, figures out exact time in clip where shot occured\n",
    "#saves all 2s clips (just for now, to compare against the noise cancellation clips that i'll try next)\n",
    "\n",
    "\n",
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import wave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from threading import Thread\n",
    "from array import array\n",
    "from scipy.io import wavfile\n",
    "from queue import Queue\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "#from gsmmodem.modem import GsmModem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('output.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 0\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "audio_analysis_queue = Queue()\n",
    "audio_analysis_time_queue = Queue()\n",
    "sound_data = np.zeros(0, dtype = \"int16\")\n",
    "audio_volume_threshold = 1000\n",
    "sms_alert_queue = Queue()\n",
    "inference_model_confidence_threshold = 0.95\n",
    "max_audio_frame_int_value = 2 ** 15 - 1\n",
    "sound_normalization_threshold = 10 ** (-1.0 / 20)\n",
    "designated_alert_recipients = [\"8163449956\", \"9176202840\", \"7857642331\"]\n",
    "\n",
    "localization_data_queue = Queue()\n",
    "localization_time_queue = Queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound_data):\n",
    "    normalization_factor = float(sound_normalization_threshold * max_audio_frame_int_value) / max(abs(i) for i in sound_data)\n",
    "    \n",
    "    # Averages the volume out\n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * normalization_factor))\n",
    "    return np.array(r, dtype = np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librosa Wrapper Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y = y, n_fft = n_fft, hop_length = hop_length, win_length = win_length)\n",
    "\n",
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length, win_length)\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.core.logamplitude(x, ref_power = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.4.2 functionality\n",
    "#     return librosa.core.amplitude_to_db(x, ref = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.6.3 functionality\n",
    "\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    return librosa.core.perceptual_weighting(x, frequencies = 1.0)  # Librosa 0.4.2 functionality\n",
    "#     return librosa.core.db_to_amplitude(x, ref = 1.0)  # Librosa 0.6.3 functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Noise Reduction Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(audio_clip,\n",
    "                noise_clip,\n",
    "                n_grad_freq = 2,\n",
    "                n_grad_time = 4,\n",
    "                n_fft = 2048,\n",
    "                win_length = 2048,\n",
    "                hop_length = 512,\n",
    "                n_std_thresh = 1.5,\n",
    "                prop_decrease = 1.0,\n",
    "                verbose = False,\n",
    "                visual = False):\n",
    "    \n",
    "    \"\"\" Removes noise from audio based upon a clip containing only noise\n",
    "\n",
    "    Args:\n",
    "        audio_clip (array): The first parameter.\n",
    "        noise_clip (array): The second parameter.\n",
    "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
    "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
    "        n_fft (int): number audio of frames between STFT columns.\n",
    "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "        hop_length (int):number audio of frames between STFT columns.\n",
    "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
    "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
    "        visual (bool): Whether to plot the steps of the algorithm\n",
    "\n",
    "    Returns:\n",
    "        array: The recovered signal with noise subtracted\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the noise sample\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # Converts the sample units to dB\n",
    "    \n",
    "    # Calculates statistics over the noise sample\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis = 1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis = 1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on noise:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the signal sample\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on signal:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Calculates value to which to mask dB\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Noise Threshold & Mask Gain in dB: \", noise_thresh, mask_gain_dB)\n",
    "    \n",
    "    # Creates a smoothing filter for the mask in time and frequency\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_freq + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_freq + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_time + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_time + 2),\n",
    "            ]\n",
    "        )[1:-1]\n",
    "    )\n",
    "    \n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "    \n",
    "    # Calculates the threshold for each frequency/time bin\n",
    "    db_thresh = np.repeat(np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "                          np.shape(sig_stft_db)[1],\n",
    "                          axis = 0).T\n",
    "    \n",
    "    # Masks segment if the signal is above the threshold\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Masking:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Convolves the mask with a smoothing filter\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask convolution:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Masks the signal\n",
    "    sig_stft_db_masked = (sig_stft_db * (1 - sig_mask)\n",
    "                          + np.ones(np.shape(mask_gain_dB))\n",
    "                          * mask_gain_dB * sig_mask)  # Masks real\n",
    "    \n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask application:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Recovers the signal\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Signal recovery:\", td(seconds=time.time() - start))\n",
    "        \n",
    "    # Returns noise-reduced audio sample\n",
    "    return recovered_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAV File Composition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves a two-second gunshot sample as a WAV file\n",
    "def create_gunshot_wav_file(gunshot, microphone_data, index, timestamp, number_of_audio_channels = audio_channels, sample_width = 2, frame_rate = 22050):\n",
    "    \n",
    "    if gunshot==1:\n",
    "        wav_file = wave.open(\"/Users/laurenogden/Downloads/gunshot\"\n",
    "                                + str(index) + \" (\"\n",
    "                                + str(timestamp) + \").wav\", \"wb\")\n",
    "        wav_file.setnchannels(number_of_audio_channels)\n",
    "        wav_file.setsampwidth(sample_width)\n",
    "        wav_file.setframerate(frame_rate)\n",
    "        wav_file.writeframes(microphone_data.reshape(44100))\n",
    "        wav_file.close()\n",
    "        \n",
    "    else:\n",
    "        wav_file = wave.open(\"/Users/laurenogden/Downloads/nongunshot\"\n",
    "                                + str(index) + \" (\"\n",
    "                                + str(timestamp) + \").wav\", \"wb\")\n",
    "        wav_file.setnchannels(number_of_audio_channels)\n",
    "        wav_file.setsampwidth(sample_width)\n",
    "        wav_file.setframerate(frame_rate)\n",
    "        wav_file.writeframes(microphone_data.reshape(44100))\n",
    "        wav_file.close()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Noise Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sample_wav = \"/Users/laurenogden/Downloads/1562604212.175424.wav\"\n",
    "noise_sample_rate, noise_sample = wavfile.read(noise_sample_wav)\n",
    "noise_clip = noise_sample[:4000]  # Finding a clip with just noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Time-Series Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_one(weights_file):\n",
    "    # Initializing 1D Time-Series Model Parameters\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_epochs = 100\n",
    "    number_of_classes = 2\n",
    "    batch_size = 32\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_shape = (44100, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 1D Time-Series Model\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = \"relu\")(x)\n",
    "    x = layers.Dense(1028, activation = \"relu\")(x)\n",
    "    \n",
    "    # Compiling 1D Time-Series Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "    \n",
    "    # Loading 1D Time-Series Model Weights\n",
    "    model.load_weights(weights_file)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Spectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_two(weights_file):\n",
    "    # 2D Spectrogram Model Parameters\n",
    "    input_shape = (128, 87, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    filter_size = (3,3)\n",
    "    maxpool_size = (3,3)\n",
    "    activation = \"relu\"\n",
    "    drop_out_rate = 0.1\n",
    "    number_of_classes = 2\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 2D Spectrogram Model\n",
    "    x = layers.Conv2D(16, filter_size, activation = activation, padding = \"same\")(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = activation)(x)\n",
    "    x = layers.Dense(1028, activation = activation)(x)\n",
    "    \n",
    "    # Compiling 2D Spectrogram Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    spec_model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    spec_model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "\n",
    "    # Loading 2D Spectrogram Model Weights\n",
    "    spec_model.load_weights(weights_file)\n",
    "    \n",
    "    return spec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreaded Inference: A callback thread adds 0.5 second samples of microphone data to the audio analysis queue; The main thread, an audio analysis thread, detects the presence of gunshot sounds in samples retrieved from the audio analysis queue; And an SMS alert thread dispatches groups of messages to designated recipients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS Alert Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sms_alert():\n",
    "    # Continuously dispatches SMS alerts to a list of designated recipients\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            logger.debug(\"ALERT: A Gunshot Has Been Detected\")\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuring the Modem Connection\n",
    "    modem_port = '/dev/ttyUSB0'\n",
    "    modem_baudrate = 115200\n",
    "    modem_sim_pin = None  # SIM card PIN (if any)\n",
    "    \n",
    "    # Establishing a Connection to the SMS Modem\n",
    "    logger.debug(\"Initializing connection to modem...\")\n",
    "    modem = GsmModem(modem_port, modem_baudrate)\n",
    "    modem.smsTextMode = False\n",
    "    modem.connect(modem_sim_pin)\n",
    "    \n",
    "    # The SMS alert thread will run indefinitely\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            try:\n",
    "                # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
    "                modem.waitForNetworkCoverage(timeout = 86400)\n",
    "                message = \"(Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "                for number in designated_alert_recipients:\n",
    "                    modem.sendSms(number, message)\n",
    "                logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "            except:\n",
    "                logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                pass\n",
    "            finally:\n",
    "                logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Localization Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from the time localization queue\n",
    "#writes out a wav file starting when a gunshot was detected and \n",
    "\n",
    "def localize():\n",
    "    \n",
    "    #variables\n",
    "    all_mic_data = []\n",
    "    #index of iteration\n",
    "    loop = 0\n",
    "    \n",
    "    #infinite loop\n",
    "    while True:\n",
    "        #get all the mic data from the queue and add it to the list\n",
    "        while True:\n",
    "            chunk = localization_data_queue.get()\n",
    "            if np.array_equal(chunk, (np.zeros((44100,), dtype = np.int16))):\n",
    "                logger.debug(\"    reached end of a gunshot group\")\n",
    "                break;\n",
    "            else:\n",
    "                all_mic_data.append(chunk) \n",
    "\n",
    "                \n",
    "        #get beginning of mic data times\n",
    "        time_at_beg_of_first_gunshot_clip = localization_time_queue.get()\n",
    "        \n",
    "        # processing\n",
    "        np_all_mic_data = np.concatenate(all_mic_data)\n",
    "        ref_all_mic_data = librosa.resample(y=np_all_mic_data, orig_sr=44100, target_sr=22050)\n",
    "        ref_all_mic_data = librosa.util.normalize(ref_all_mic_data)\n",
    "        \n",
    "        #write out a soundfile of the entire chunk\n",
    "        with sf.SoundFile(\"/Users/laurenogden/Downloads/\" + str(loop) + \"__\" + time.ctime(time_at_beg_of_first_gunshot_clip) + \".wav\", mode='wb', samplerate=22050, channels=1) as file:\n",
    "            file.write(ref_all_mic_data)\n",
    "        logger.debug(\"    wrote out the #\" + str(loop) + \"chunk, size: \" + str(len(ref_all_mic_data)))\n",
    "\n",
    " \n",
    "        #figure out the times of the gunshots in the clip\n",
    "        #sort the data, figure out the threshold\n",
    "        sorted_data = np.sort(ref_all_mic_data)\n",
    "        threshold = sorted_data[len(sorted_data) - int(len(sorted_data)*0.001)]\n",
    "\n",
    "        #find all values above that threshold\n",
    "        above_threshold = []\n",
    "        for i in range(0, len(ref_all_mic_data)):\n",
    "            if ref_all_mic_data[i] > threshold:\n",
    "                above_threshold.append(i)\n",
    "                \n",
    "        #separate out individual gunshots from that whole chunk\n",
    "        distinct_shots = []\n",
    "        distinct_shots.append(above_threshold[0])\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            #if within 5ms of each other, assume from same shot\n",
    "            if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "                distinct_shots.append(above_threshold[i])\n",
    "\n",
    "        #times relative to beginning of the saved clip\n",
    "        logger.debug(\"There were \" + str(len(distinct_shots)) + \" distinct shots detected at \" + str(time.ctime(time_at_beg_of_first_gunshot_clip)))\n",
    "        for i in distinct_shots:\n",
    "            logger.debug(i/22050)\n",
    "            \n",
    "        #times in general\n",
    "        #logger.debug(\"The exact times of the gunshots were: \")\n",
    "        #for i in distinct_shots:\n",
    "            #logger.debug(time_at_beg_of_first_gunshot_clip + i/22050 - 2)\n",
    "            #logger.debug(time.ctime(time_at_beg_of_first_gunshot_clip + i/22050 - 2))\n",
    "\n",
    "            \n",
    "        #clear all mic data to be ready for the next clip\n",
    "        del all_mic_data[:]\n",
    "        #increase index\n",
    "        loop += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global sound_data\n",
    "    sound_buffer = np.frombuffer(in_data, dtype = \"int16\")\n",
    "    sound_data = np.append(sound_data, sound_buffer)\n",
    "    if len(sound_data) >= 88200:\n",
    "        audio_analysis_queue.put(sound_data)\n",
    "        #put the time on a separate queue\n",
    "        current_time = time.time()\n",
    "        audio_analysis_time_queue.put(current_time)\n",
    "        #empty out sound_data\n",
    "        sound_data = np.zeros(0, dtype = \"int16\")\n",
    "        \n",
    "    return (sound_buffer, pyaudio.paContinue)\n",
    "\n",
    "pa = pyaudio.PyAudio()\n",
    "\n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True,\n",
    "                 stream_callback = callback)\n",
    "\n",
    "# Starts the callback thread\n",
    "stream.start_stream()\n",
    "logger.debug(\"--- Listening to Audio Stream ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Starts the SMS alert thread\n",
    "sms_alert_thread = Thread(target = send_sms_alert)\n",
    "sms_alert_thread.start()\n",
    "\n",
    "#starting the time localization thread\n",
    "#time_localization_thread = Thread(target = localization)\n",
    "#time_localization_thread.start()\n",
    "\n",
    "# Loading 1D Time-Series Model\n",
    "model = load_model_one(\"../models/gunshot_sound_model.h5\")\n",
    "    \n",
    "# Loading 2D Spectrogram Model\n",
    "#   model = load_model_two(\"./models/gunshot_sound_model_spectrograph_model.h5\")\n",
    "    \n",
    "# An iterator variable for counting the number of gunshot sounds detected\n",
    "gunshot_sound_counter = 1\n",
    "\n",
    "loop_counter = 0\n",
    "\n",
    "#booleans for detection status\n",
    "detected = False\n",
    "detected_first = False\n",
    "detected_again = False\n",
    "end_of_detections = False\n",
    "\n",
    "\n",
    "# The main (audio analysis) thread will run indefinitely\n",
    "while True:\n",
    "    \n",
    "    # Gets a sample and its timestamp from the audio analysis queue\n",
    "    microphone_data = np.array(audio_analysis_queue.get(), dtype = \"int16\")\n",
    "    time_of_sample_occurrence = audio_analysis_time_queue.get()\n",
    "    \n",
    "\n",
    "    # Outputs the current sample's maximum frequency value\n",
    "    maximum_frequency_value = max(microphone_data)\n",
    "    logger.debug(\"The maximum frequency value of a given sample: \" + str(maximum_frequency_value))\n",
    "        \n",
    "    # Determines whether a given sample potentially contains a gunshot\n",
    "    if maximum_frequency_value >= audio_volume_threshold:\n",
    "        # Post-processes the microphone data\n",
    "        modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "        logger.debug(\"resampled length: \" + str(len(modified_microphone_data)))\n",
    "        modified_microphone_data = normalize(modified_microphone_data)\n",
    "        logger.debug(\"normalized length: \" + str(len(modified_microphone_data)))\n",
    "        modified_microphone_data = remove_noise(audio_clip = modified_microphone_data, noise_clip = noise_clip)  # As a substitute for normalization\n",
    "       \n",
    "        logger.debug(\"noise removed length: \" + str(len(modified_microphone_data)))\n",
    "        number_of_missing_sample_hertz = 44100 - len(modified_microphone_data)\n",
    "        if number_of_missing_sample_hertz > 0:\n",
    "            modified_microphone_data = np.array(modified_microphone_data.tolist() + [0 for i in range(number_of_missing_sample_hertz)])\n",
    "       \n",
    "        modified_microphone_data = modified_microphone_data[:44100]\n",
    "        logger.debug(\"sliced length: \" + str(len(modified_microphone_data))) \n",
    "        modified_microphone_data = modified_microphone_data.reshape(-1, 44100, 1)\n",
    "        \n",
    "\n",
    "        # Passes a given audio sample into the model for prediction\n",
    "        probabilities = model.predict(modified_microphone_data)\n",
    "        logger.debug(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "        #logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])\n",
    "\n",
    "        # Determines if a gunshot sound was detected by the model\n",
    "        if (probabilities[0][1] >= inference_model_confidence_threshold):\n",
    "            \n",
    "            # Sends out an SMS alert\n",
    "            sms_alert_queue.put(\"Gunshot Detected\")\n",
    "            \n",
    "            # Makes a WAV file of the gunshot sample\n",
    "            create_gunshot_wav_file(1, modified_microphone_data, gunshot_sound_counter, time_of_sample_occurrence)\n",
    "\n",
    "            # Increments the counter for gunshot sound file names\n",
    "            gunshot_sound_counter += 1\n",
    "            \n",
    "            '''\n",
    "            #time localization in here \n",
    "            #figure out the times of the gunshots in the clip\n",
    "            #sort the data, figure out the threshold\n",
    "            modified_microphone_data = modified_microphone_data.reshape(44100)\n",
    "            sorted_data = np.sort(modified_microphone_data)\n",
    "            threshold = sorted_data[len(sorted_data) - int(len(sorted_data)*0.001)]\n",
    "\n",
    "            #find all values above that threshold\n",
    "            above_threshold = []\n",
    "            for i in range(0, len(modified_microphone_data)):\n",
    "                if modified_microphone_data[i] > threshold:\n",
    "                    above_threshold.append(i)\n",
    "\n",
    "            #separate out individual gunshots from that whole chunk\n",
    "            distinct_shots = []\n",
    "            distinct_shots.append(above_threshold[0])\n",
    "            for i in range(1, len(above_threshold)):\n",
    "                #if within 5ms of each other, assume from same shot\n",
    "                if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "                    distinct_shots.append(above_threshold[i])\n",
    "\n",
    "            #times relative to beginning of the saved clip\n",
    "            logger.debug(\"There were \" + str(len(distinct_shots)) + \" distinct shots detected at \" + str(time.ctime(time_of_sample_occurrence)))\n",
    "            for i in distinct_shots:\n",
    "                logger.debug(i/22050)\n",
    "                times_of_shots.append(time_of_sample_occurrence + i/22050)\n",
    "                \n",
    "            '''\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            #update booleans w detection state \n",
    "            if not detected:\n",
    "                detected = True\n",
    "                detected_first = True\n",
    "            else:\n",
    "                detected_first = False\n",
    "                detected_again = True\n",
    "                    \n",
    "        else:\n",
    "            # Makes a WAV file of the nongunshot sample\n",
    "            create_gunshot_wav_file(0, modified_microphone_data, loop_counter, time_of_sample_occurrence)\n",
    "\n",
    "            #update booleans w detection state\n",
    "            if detected:\n",
    "                end_of_detections = True\n",
    "            else:\n",
    "                end_of_detections = False\n",
    "            detected = False\n",
    "            detected_first = False\n",
    "            detected_again = False\n",
    "            \n",
    "    else:\n",
    "        #update booleans w detection state\n",
    "        if detected:\n",
    "            end_of_detections = True\n",
    "        else:\n",
    "            end_of_detections = False\n",
    "        detected = False\n",
    "        detected_first = False\n",
    "        detected_again = False\n",
    "        \n",
    "        #based on booleans, put microphone data or prev mic data on the time localization queue\n",
    "        if detected_first:\n",
    "            localization_data_queue.put(prev_mic_data)\n",
    "            localization_data_queue.put(microphone_data)\n",
    "            localization_time_queue.put(time_of_sample)\n",
    "        if detected_again:\n",
    "            localization_data_queue.put(microphone_data)\n",
    "        if end_of_detections:\n",
    "            localization_data_queue.put(microphone_data)\n",
    "            localization_data_queue.put(np.zeros((44100,), dtype = np.int16))\n",
    "            end_of_detections = False\n",
    "            \n",
    "        # Makes a WAV file of the nongunshot sample\n",
    "        create_gunshot_wav_file(0, modified_microphone_data, loop_counter, time_of_sample_occurrence)\n",
    "\n",
    "\n",
    "                    \n",
    "    #keep track of the previous microphone data\n",
    "    prev_mic_data = microphone_data\n",
    "\n",
    "    loop_counter+=1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "times_of_shots.sort()\n",
    "\n",
    "times_of_distinct_shots = []\n",
    "times_of_distinct_shots.append(times_of_shots[0])\n",
    "j = 0\n",
    "\n",
    "for i in range(1, len(times_of_shots)):\n",
    "    #print(\"diff from before:\" times_of_shots[i] - times_of_shots[i-1])\n",
    "    #print(times_of_shots[i] - times_of_distinct_shots[j])\n",
    "    if times_of_shots[i] - times_of_shots[i-1] > 0.05:\n",
    "        times_of_distinct_shots.append(times_of_shots[i])\n",
    "        j += 1\n",
    "        \n",
    "        \n",
    "print(\"# shots: \" + str(len(times_of_shots)))\n",
    "print(\"# distinct shots: \" + str(len(times_of_distinct_shots)))\n",
    "\n",
    "print(\"all:\")\n",
    "for a in times_of_shots:\n",
    "    print(a)\n",
    "    \n",
    "print(\"distinct:\")\n",
    "for b in times_of_distinct_shots:\n",
    "    print(b)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing A Model with Sample Audio (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model_one(\"./models/gunshot_sound_model.h5\")\n",
    "# training_sample, sr = librosa.load(\"./recordings/260600_8.wav\")\n",
    "# training_sample = normalize(training_sample)\n",
    "# number_of_missing_hertz = 44100 - len(training_sample)\n",
    "# training_sample = np.array(training_sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "# training_sample = training_sample.reshape(-1, 44100, 1)\n",
    "# probabilities = model.predict(training_sample)\n",
    "# logger.debug(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "# logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
