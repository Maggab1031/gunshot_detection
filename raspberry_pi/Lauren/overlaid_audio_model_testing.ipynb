{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to record X mins of audio, overlay gunshot clips on top of it, run inference on it with both the 1D and 2D\n",
    "#tflite models, and output precision, recall, etc, in order to evaluate the performance of models\n",
    "    #can easily jump to overlaying clips/inference if you already have a recording (jump down to \"Run models on\n",
    "    #overlaid audio\" section)\n",
    "    \n",
    "#for sliding predictions it's a bit harder to calculate the metrics -- be wary of them I'd say\n",
    "    \n",
    "    \n",
    "import pyaudio\n",
    "import librosa\n",
    "import wave\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from array import array\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "import scipy.signal\n",
    "from queue import Queue\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import six\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 2\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "sound_data = np.zeros(0, dtype = \"int16\")\n",
    "sound_normalization_threshold = 10 ** (-1.0 / 20)\n",
    "max_audio_frame_int_value = 2 ** 15 - 1\n",
    "confidence_level = 0.50\n",
    "\n",
    "#how long to record audio for (in minutes)\n",
    "recording_length = 30\n",
    "\n",
    "#directory to save files to\n",
    "#for my laptop\n",
    "files_directory = \"/Users/laurenogden/Downloads/\"\n",
    "#relative path to directory on github\n",
    "#files_directory = \"../recordings/\"\n",
    "\n",
    "#directory of gunshot files to put on top of data (2s or less long files)\n",
    "gunshot_directory = files_directory + \"Original Gunshot Trimmed/\"\n",
    "\n",
    "audio_analysis_queue = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization function\n",
    "def normalize(sound_data):\n",
    "    \n",
    "    absolute_maximum_sound_datum = max(abs(i) for i in sound_data)\n",
    "    # Prevents a divide by zero scenario\n",
    "    if absolute_maximum_sound_datum == 0.0:\n",
    "        absolute_maximum_sound_datum = 0.001\n",
    "        \n",
    "    normalization_factor = float(sound_normalization_threshold * max_audio_frame_int_value) / absolute_maximum_sound_datum\n",
    "    \n",
    "    # Averages the volume out\n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * normalization_factor))\n",
    "    return np.array(r, dtype = np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save a wav file\n",
    "def create_wav_file(microphone_data, name):\n",
    "    librosa.output.write_wav(files_directory + name + \".wav\", microphone_data, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the times of each sound (mins : secs)\n",
    "def time_in_mins(index):\n",
    "    secs = index/22050\n",
    "    return str(int(secs//60)) + \":\" + str(secs%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a spectrogram for 2D CNN ~~ OLD\n",
    "def convert_to_spectrogram(data, sample_rate):\n",
    "    return np.array(librosa.feature.melspectrogram(y = data, sr = sample_rate), dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to make a spectrogram image for other 2D CNN ~~ OLD\n",
    "def power_to_db(S, ref = 1.0, amin = 1e-10, top_db = 80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        print('ParameterError: amin must be strictly positive')\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        print('Warning: power_to_db was called on complex input so phase '\n",
    "                      'information will be discarded. To suppress this warning, '\n",
    "                      'call power_to_db(np.abs(D)**2) instead.')\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            print('ParameterError: top_db must be non-negative')\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def convert_spectrogram_to_image(spectrogram):\n",
    "    plt.interactive(False)\n",
    "    \n",
    "    figure = plt.figure(figsize = [0.72, 0.72], dpi = 400)\n",
    "    plt.tight_layout(pad = 0)\n",
    "    ax = figure.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    librosa.display.specshow(power_to_db(spectrogram, ref = np.max))\n",
    "    \n",
    "    canvas = FigureCanvas(figure)\n",
    "    canvas.draw()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "\n",
    "    image = np.fromstring(figure.canvas.tostring_rgb(), dtype = \"uint8\")\n",
    "    image = image.reshape((width, height, 3))\n",
    "    image = cv2.resize(image, (192, 192))\n",
    "\n",
    "    # Cleaning up the matplotlib instance\n",
    "    plt.close()    \n",
    "    figure.clf()\n",
    "    plt.close(figure)\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    # Returns a NumPy array containing an image of a spectrogram\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to make a spectrogram ~~ NEW\n",
    "\n",
    "SAMPLE_RATE_PER_SECOND = 22050\n",
    "SAMPLE_RATE_PER_TWO_SECONDS = 44100\n",
    "HOP_LENGTH = 345 * 2\n",
    "MINIMUM_FREQUENCY = 20\n",
    "MAXIMUM_FREQUENCY = SAMPLE_RATE_PER_SECOND\n",
    "NUMBER_OF_MELS = 128\n",
    "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
    "\n",
    "def convert_audio_to_spectrogram(data):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=data, sr=SAMPLE_RATE_PER_TWO_SECONDS,\n",
    "                                                 hop_length=HOP_LENGTH,\n",
    "                                                 fmin=MINIMUM_FREQUENCY,\n",
    "                                                 fmax=MAXIMUM_FREQUENCY,\n",
    "                                                 n_mels=NUMBER_OF_MELS,\n",
    "                                                 n_fft=NUMBER_OF_FFTS)\n",
    "    spectrogram = power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        logger.debug(\"ParameterError: amin must be strictly positive\")\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        logger.debug(\"Warning: power_to_db was called on complex input so phase information will be discarded.\")\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            logger.debug(\"ParameterError: top_db must be non-negative\")\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label binarizer\n",
    "labels = np.load(\"/Users/laurenogden/Downloads/gunshot_augmented_sound_labels.npy\")\n",
    "labels = np.array([(\"gun_shot\" if label == 1 else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auc metric for loading original models\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback function for pyaudio strean\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global sound_data\n",
    "    sound_buffer = np.frombuffer(in_data, dtype = \"int16\")\n",
    "    sound_data = np.append(sound_data, sound_buffer)\n",
    "    if len(sound_data) >= 88200:\n",
    "        audio_analysis_queue.put(sound_data)\n",
    "        #empty out sound_data\n",
    "        sound_data = np.zeros(0, dtype = \"int16\")\n",
    "\n",
    "    return (sound_buffer, pyaudio.paContinue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record X mins of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open pyaudio stream\n",
    "pa = pyaudio.PyAudio()\n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True,\n",
    "                 stream_callback = callback)\n",
    "\n",
    "# Starts the callback thread\n",
    "stream.start_stream()\n",
    "\n",
    "#get first bit of mic data from the stream\n",
    "mic_data = audio_analysis_queue.get()\n",
    "mod_mic_data = librosa.resample(y = mic_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "mod_mic_data = normalize(mod_mic_data)\n",
    "mic_data = mod_mic_data\n",
    "#create_wav_file(mod_mic_data, \"-1_\" + str(time.time()))\n",
    "\n",
    "#get 10 mins of audio data (300 2s clips)\n",
    "for i in range(0, recording_length*30 - 1):\n",
    "    #print(time.ctime(time.time()))\n",
    "    new_data = np.array(audio_analysis_queue.get(), dtype = \"int16\")\n",
    "    mod_new_data = librosa.resample(y = new_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "    mod_mic_data = normalize(mod_new_data)\n",
    "    #create_wav_file(mod_new_data, str(i) + \"_\" + str(time.time()))\n",
    "    mic_data = np.append(mic_data, mod_new_data)\n",
    "\n",
    "#save the clip\n",
    "createwav_file(mic_data, str(recording_length) + \"_mins_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mark loud noises in noise clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mark locations of loud noises in the clips (taps/claps/etc)\n",
    "\n",
    "#sort the data, figure out the threshold\n",
    "sorted_data = np.sort(mic_data)\n",
    "threshold = sorted_data[len(sorted_data) - int(len(sorted_data)*0.001)]\n",
    "\n",
    "#find all values above that threshold\n",
    "above_threshold = []\n",
    "for i in range(0, len(mic_data)):\n",
    "    if mic_data[i] > threshold:\n",
    "        above_threshold.append(i)\n",
    "\n",
    "#separate out individual sounds from that whole chunk\n",
    "distinct_sounds = []\n",
    "distinct_sounds.append(above_threshold[0])\n",
    "for i in range(1, len(above_threshold)):\n",
    "    #if within 5ms of each other, assume from same shot\n",
    "    if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "        distinct_sounds.append(above_threshold[i])\n",
    "\n",
    "#times relative to beginning of the saved clip\n",
    "print(\"There were \" + str(len(distinct_sounds)) + \" distinct loud sounds detected\")\n",
    "distinct_times = []\n",
    "for i in distinct_sounds:\n",
    "    distinct_times.append(i/22050)\n",
    "    \n",
    "#save them in a txt file for future possible use\n",
    "loud_noises_file = open(files_directory + \"background_loud_noises_indices.txt\", \"w\")\n",
    "for i in distinct_sounds:\n",
    "    loud_noises_file.write(str(i)+\"\\n\")\n",
    "loud_noises_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay gunshot clips onto recorded noise clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load back the X min clip saved above (or whenever, idc)\n",
    "#10mins_lab is the 10 minutes I recorded on the Sizheng mic just sitting in the lab\n",
    "    #has some people talking, me tapping the mic, moving my water bottle, etc\n",
    "#noise, rate = librosa.load(files_directory + \"10mins_lab.wav\") \n",
    "#mohler_outside.wav is what I named the hour long audio clip Dr. Mohler recorded outside his house on the Sizheng\n",
    "    #I'm only reading in half an hour of it because the whole hour seems like a lot\n",
    "noise, rate = librosa.load(files_directory + \"mohler_outside.wav\", duration = 60*recording_length) \n",
    "#noise, rate = librosa.load(files_directory + str(recording_length) + \"_mins_background.wav\")\n",
    "\n",
    "#list files in a gunshot audio directory\n",
    "gunshot_files = os.listdir(gunshot_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a numpy array the size of your clip, fill it with zeros\n",
    "all_gunshots = np.zeros(len(noise), dtype = \"float32\")\n",
    "\n",
    "#how many gunshot clips to put on top of your audio\n",
    "n_gunshot_files_to_use = 125\n",
    "\n",
    "locs = []\n",
    "locs_of_actual_shots = []\n",
    "files_used = []\n",
    "#add gunshots to that 0 numpy array\n",
    "for i in range(0, n_gunshot_files_to_use):\n",
    "    #pick a random gunshot file\n",
    "    file = gunshot_files[np.random.randint(0, len(gunshot_files))]\n",
    "    #avoid using the exact same gunshot twice, or attempting to load a non-wav file in the folder\n",
    "    while file in files_used or \".wav\" not in file:\n",
    "        file = gunshot_files[np.random.randint(0, len(gunshot_files))]\n",
    "    files_used.append(file)\n",
    "    #load the file\n",
    "    gunshot, sr = librosa.load(gunshot_directory + file)\n",
    "    \n",
    "    \n",
    "    #find the location(s) of the actual gunshot(s) in that file\n",
    "    #sort the data, figure out the threshold\n",
    "    sorted_gunshot_data = np.sort(gunshot)\n",
    "    threshold = sorted_gunshot_data[len(sorted_gunshot_data) - int(len(sorted_gunshot_data)*0.001)]\n",
    "    #find all values above that threshold\n",
    "    above_threshold = []\n",
    "    for i in range(0, len(gunshot)):\n",
    "        if gunshot[i] > threshold:\n",
    "            above_threshold.append(i)\n",
    "    #separate out individual sounds from that whole chunk\n",
    "    distinct_shots = []\n",
    "    distinct_shots.append(above_threshold[0])\n",
    "    for i in range(1, len(above_threshold)):\n",
    "        #if within 5ms of each other, assume from same shot\n",
    "        if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "            distinct_shots.append(above_threshold[i])\n",
    "    \n",
    "    \n",
    "    #pick a random location to put it at \n",
    "    loc = np.random.randint(0, len(noise) - 44100)\n",
    "    #to avoid putting two gunshots at the exact same place in the clip\n",
    "        #to be improved potentially to avoid overlapping gunshots??\n",
    "    while loc in locs:\n",
    "        loc = np.random.randint(0, len(noise))\n",
    "    locs.append(loc)\n",
    "    #append location(s) of the actual gunshot(s) in the entire clip\n",
    "    for i in distinct_shots:\n",
    "        locs_of_actual_shots.append(loc+i)\n",
    "    \n",
    "    #print(\"putting \" + file + \" at location \" + str(loc) + \", time= \" + time_in_mins(loc))\n",
    "    \n",
    "    #place the data at that location\n",
    "    for j in range(loc, loc+len(gunshot)):\n",
    "        all_gunshots[j] = all_gunshots[j] + gunshot[j-loc]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the noise clip with the gunshot array and save it\n",
    "overlaid = noise * 0.5 + all_gunshots * 0.5\n",
    "overlaid_normed = normalize(overlaid)\n",
    "#create_wav_file(overlaid_normed, str(recording_length) + \"_mins_overlaid_1_0.7x1.0\")\n",
    "create_wav_file(overlaid, str(recording_length) + \"_mins_overlaid_2_0.5x0.5_not_normed\")\n",
    "\n",
    "#save the audio of just the gunshots w silence in the back (no noise clip) to see how the model does on that as well\n",
    "create_wav_file(all_gunshots, str(recording_length) + \"_only_gunshots_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save locations of gunshots in new overlaid clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 194 gunshots\n",
      "NO SLIDING: There are 128 2s clips in our 30.0 min recording containing gunshots\n",
      "SLIDING EVERY HALF SECOND: There are 152 2s clips in our 30.0 min recording containing gunshots\n",
      "SLIDING EVERY SECOND: There are 142 2s clips in our 30.0 min recording containing gunshots\n"
     ]
    }
   ],
   "source": [
    "#sort the list of locations of actual gunshots, print out their time locations (if you wanna)\n",
    "print(\"Added \" + str(len(locs_of_actual_shots)) + \" gunshots\")\n",
    "locs_of_actual_shots.sort()\n",
    "'''\n",
    "print(\"Times of the gunshots in the recording: \")\n",
    "for i in locs_of_actual_shots:\n",
    "    print(\"location = \" + str(i) + \" at time = \" + str(time_in_mins(i)))\n",
    "'''\n",
    "    \n",
    "#figure out what two second clips contain gunshots\n",
    "clips_w_guns = []\n",
    "for i in locs_of_actual_shots:\n",
    "    if (i//44100)*44100 not in clips_w_guns:\n",
    "        clips_w_guns.append((i//44100)*44100)\n",
    "        \n",
    "#sliding every half second, this tells you the clips that have gunshots right at the very beginning\n",
    "clips_sliding_half_w_guns = []\n",
    "for i in locs_of_actual_shots:\n",
    "    if (i//11025)*11025 not in clips_sliding_half_w_guns:\n",
    "        clips_sliding_half_w_guns.append((i//11025)*11025)\n",
    "        \n",
    "#sliding every second, same sorta deal  \n",
    "clips_sliding_one_w_guns = []\n",
    "for i in locs_of_actual_shots:\n",
    "    if (i//22050)*22050 not in clips_sliding_one_w_guns:\n",
    "        clips_sliding_one_w_guns.append((i//22050)*22050)\n",
    "        \n",
    "\n",
    "print(\"NO SLIDING: There are \" + str(len(clips_w_guns)) + \" 2s clips in our \" + str(len(noise)/22050/60) \n",
    "      + \" min recording containing gunshots\")\n",
    "\n",
    "print(\"SLIDING EVERY HALF SECOND: There are \" + str(len(clips_sliding_half_w_guns)) + \" 2s clips in our \" + str(len(noise)/22050/60) \n",
    "      + \" min recording containing gunshots\")\n",
    "\n",
    "print(\"SLIDING EVERY SECOND: There are \" + str(len(clips_sliding_one_w_guns)) + \" 2s clips in our \" + str(len(noise)/22050/60) \n",
    "      + \" min recording containing gunshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the locations of gunshots in a textfile for later use\n",
    "locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_2_exact_locations.txt\", \"w\")\n",
    "for i in locs_of_actual_shots:\n",
    "    locations_file.write(str(i)+\"\\n\")\n",
    "locations_file.close()\n",
    "\n",
    "#save the indices of the clips with guns in a textfile for later use: no sliding\n",
    "locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_2_indices_no_sliding.txt\", \"w\")\n",
    "for i in clips_w_guns:\n",
    "    locations_file.write(str(i)+\"\\n\")\n",
    "locations_file.close()\n",
    "\n",
    "#save the indices of the clips with guns in a textfile for later use: sliding every half second\n",
    "locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_2_indices_sliding_half.txt\", \"w\")\n",
    "for i in clips_sliding_half_w_guns:\n",
    "    locations_file.write(str(i)+\"\\n\")\n",
    "locations_file.close()\n",
    "\n",
    "#save the indices of the clips with guns in a textfile for later use: sliding every second\n",
    "locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_2_indices_sliding_one.txt\", \"w\")\n",
    "for i in clips_sliding_one_w_guns:\n",
    "    locations_file.write(str(i)+\"\\n\")\n",
    "locations_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models on overlaid audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load back in the clip overlaid with gunshots\n",
    "input_audio_file = files_directory + str(recording_length) + \"_mins_overlaid_2_0.5x0.5_not_normed.wav\"\n",
    "#input_audio_file = files_directory + str(recording_length) + \"_only_gunshots_2.wav\"\n",
    "#input_audio_file = files_directory + str(recording_length) + \"_mins_background.wav\"\n",
    "#input_audio_file = files_directory + \"mohler_outside.wav\"\n",
    "\n",
    "audio, sr = librosa.load(input_audio_file, duration = 60*recording_length)\n",
    "\n",
    "#load back the indices of clips that contain gunshots from the txt file, choosing how much you want to slide\n",
    "sliding_half = False\n",
    "sliding_one = False\n",
    "if sliding_half:\n",
    "    locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_2_indices_sliding_half.txt\", \"r\")\n",
    "elif sliding_one:\n",
    "    locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_2_indices_sliding_one.txt\", \"r\")\n",
    "else:\n",
    "    locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_2_indices_no_sliding.txt\", \"r\")\n",
    "\n",
    "clips_w_guns = locations_file.readlines()\n",
    "locations_file.close()\n",
    "#turn strings to ints\n",
    "clips_w_guns = list(map(int, clips_w_guns))\n",
    "\n",
    "#are we using the forgiving way of classification\n",
    "forgiving = True\n",
    "\n",
    "exact_locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_2_exact_locations.txt\", \"r\")\n",
    "exact_locs = exact_locations_file.readlines()\n",
    "exact_locations_file.close()\n",
    "#turn strings to ints\n",
    "exact_locs = list(map(int, exact_locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open a file to info about the audio clip, modes, eventually metrics, etc\n",
    "metrics_filename = files_directory + \"model_metrics_21.txt\"\n",
    "metrics_file = open(metrics_filename, \"w\")\n",
    "#audio file we're analyzing\n",
    "metrics_file.write(\"Analyzing audio file: \" + input_audio_file + \"\\n\")\n",
    "#how many clips there are in it w gunshots\n",
    "metrics_file.write(\"There are \" + str(recording_length*30) + \" 2 second clips, \" \n",
    "                           + str(len(clips_w_guns)) + \" of which contain gunshots.\\n\")\n",
    "#confidence level\n",
    "metrics_file.write(\"Predictions were done at a confidence level of \" + str(confidence_level) + \"\\n\")\n",
    "\n",
    "#are we sliding\n",
    "if sliding_half:\n",
    "    metrics_file.write(\"Sliding predictions were done every half second\\n\")\n",
    "elif sliding_one:\n",
    "    metrics_file.write(\"Sliding predictions were done every second\\n\")\n",
    "else:\n",
    "    metrics_file.write(\"Predictions were done every 2 seconds (no sliding)\\n\")\n",
    "\n",
    "#are you using forgiving true positive classification (see below)\n",
    "if forgiving:\n",
    "    metrics_file.write(\"Using forgiving true positive classification \\n\\n\")\n",
    "else:\n",
    "    metrics_file.write(\"Using strict true positive classification \\n\\n\")\n",
    "\n",
    "metrics_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 1D tflite model\n",
    "model_name_1D = \"gunshot_sound_model_1d.tflite\"\n",
    "interpreter_1D = tf.lite.Interpreter(model_path = \"../models/\" + model_name_1D)\n",
    "interpreter_1D.allocate_tensors()\n",
    "# Get input and output tensors.\n",
    "input_details_1D = interpreter_1D.get_input_details()\n",
    "output_details_1D = interpreter_1D.get_output_details()\n",
    "input_shape_1D = input_details_1D[0]['shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 2D tflite model\n",
    "model_name_2D = \"spectrogram_gunshot_model_1.tflite\"\n",
    "interpreter_2D = tf.lite.Interpreter(model_path = \"../models/\" + model_name_2D)\n",
    "interpreter_2D.allocate_tensors()\n",
    "# Get input and output tensors.\n",
    "input_details_2D = interpreter_2D.get_input_details()\n",
    "output_details_2D = interpreter_2D.get_output_details()\n",
    "input_shape_2D = input_details_2D[0]['shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ryan's 2D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 2D tflite model\n",
    "model_name_ryan = \"RYAN_LATEST_gunshot_2d_spectrogram_model.tflite\"\n",
    "interpreter_2D_ryan = tf.lite.Interpreter(model_path = \"../models/\" + model_name_ryan)\n",
    "interpreter_2D_ryan.allocate_tensors()\n",
    "# Get input and output tensors.\n",
    "input_details_2D_ryan = interpreter_2D_ryan.get_input_details()\n",
    "output_details_2D_ryan = interpreter_2D_ryan.get_output_details()\n",
    "input_shape_2D_ryan = input_details_2D_ryan[0]['shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D 128x128 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 2D tflite model\n",
    "model_name_128x128 = \"128_128_gunshot_2d_spectrogram_model.tflite\"\n",
    "interpreter_2D_128x128 = tf.lite.Interpreter(model_path = \"../models/\" + model_name_ryan)\n",
    "interpreter_2D_128x128.allocate_tensors()\n",
    "# Get input and output tensors.\n",
    "input_details_2D_128x128 = interpreter_2D_128x128.get_input_details()\n",
    "output_details_2D_128x128 = interpreter_2D_128x128.get_output_details()\n",
    "input_shape_2D_128x128 = input_details_2D_128x128[0]['shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_1D = []\n",
    "positives_2D = []\n",
    "positives_2D_ryan = []\n",
    "all_positives = []\n",
    "all_positives_and = []\n",
    "\n",
    "#pass two second slices into each of the models to predict\n",
    "#slide every 1 second\n",
    "for i in range (0, len(audio) - 22050, 22050):\n",
    "#slide every half second\n",
    "#for i in range(0, len(audio) - 33075, 11025):\n",
    "#no sliding, discrete 2 second chunks\n",
    "#for i in range (0, len(audio), 44100):\n",
    "    audio_slice = audio[i:i+44100]\n",
    "    \n",
    "    #Normalize\n",
    "    #audio_slice = normalize(audio_slice)\n",
    "\n",
    "    #1D reshaping\n",
    "    reshaped_audio_slice_1D = audio_slice.reshape(input_shape_1D)\n",
    "    #1D predictions\n",
    "    input_tensor_1D = tf.convert_to_tensor(reshaped_audio_slice_1D, np.float32)\n",
    "    interpreter_1D.set_tensor(input_details_1D[0][\"index\"], reshaped_audio_slice_1D.astype(\"float32\"))\n",
    "    interpreter_1D.invoke()\n",
    "    probabilities_1D = interpreter_1D.get_tensor(output_details_1D[0][\"index\"])\n",
    "    #print(\"1D model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_1D[:, 0])[0])\n",
    "    if probabilities_1D[0][1] >= confidence_level:\n",
    "        #create_wav_file(audio_slice, str(i))\n",
    "        positives_1D.append(i) \n",
    "        #print(\"        POSITIVE, APPENDED\")\n",
    "        \n",
    "        \n",
    "    #2D reshaping\n",
    "    reshaped_audio_slice_2D = convert_to_spectrogram(data = audio_slice, sample_rate = 22050)\n",
    "    reshaped_audio_slice_2D = reshaped_audio_slice_2D.reshape(input_shape_2D)\n",
    "    #2D predictions\n",
    "    input_tensor_2D = tf.convert_to_tensor(reshaped_audio_slice_2D, np.float32)\n",
    "    interpreter_2D.set_tensor(input_details_2D[0][\"index\"], reshaped_audio_slice_2D)\n",
    "    interpreter_2D.invoke()\n",
    "    probabilities_2D = interpreter_2D.get_tensor(output_details_2D[0][\"index\"])\n",
    "    #print(\"2D model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_2D[:, 0])[0])\n",
    "    if probabilities_2D[0][1] >= confidence_level:\n",
    "        #create_wav_file(audio_slice, str(i))\n",
    "        positives_2D.append(i) \n",
    "        #print(\"        POSITIVE, APPENDED\")\n",
    "    \n",
    "    \n",
    "    #Ryan 2D reshaping\n",
    "    reshaped_audio_slice_2D_ryan = convert_audio_to_spectrogram(data = audio_slice)\n",
    "    #reshaped_audio_slice_2D_ryan = convert_spectrogram_to_ryan(spectrogram = reshaped_audio_slice_2D_ryan)\n",
    "    reshaped_audio_slice_2D_ryan = reshaped_audio_slice_2D_ryan.reshape(input_shape_2D_ryan)\n",
    "    reshaped_audio_slice_2D_ryan = reshaped_audio_slice_2D_ryan.astype(\"float32\")\n",
    "    #reshaped_audio_slice_2D_ryan /= 255\n",
    "    #Ryan 2D Image predictions\n",
    "    input_tensor_2D_ryan = tf.convert_to_tensor(reshaped_audio_slice_2D_ryan, np.float32)\n",
    "    interpreter_2D_ryan.set_tensor(input_details_2D_ryan[0][\"index\"], reshaped_audio_slice_2D_ryan)\n",
    "    interpreter_2D_ryan.invoke()\n",
    "    probabilities_2D_ryan = interpreter_2D_ryan.get_tensor(output_details_2D_ryan[0][\"index\"])\n",
    "    #print(\"Ryan 2D model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_2D_ryan[:, 0])[0])\n",
    "    if probabilities_2D_ryan[0][1] >= confidence_level:\n",
    "        #create_wav_file(audio_slice, str(i))\n",
    "        positives_2D_ryan.append(i)\n",
    "        #print(\"        POSITIVE, APPENDED\")\n",
    "        \n",
    "        \n",
    "    #if any of them predicted it as a gunshot, it's positive\n",
    "    if probabilities_1D[0][1] >= confidence_level or probabilities_2D[0][1] >= confidence_level or probabilities_2D_ryan[0][1] >= confidence_level:\n",
    "        all_positives.append(i)\n",
    "    \n",
    "    #if all of them predicted it as a gunshot, it's positive\n",
    "    if probabilities_1D[0][1] >= confidence_level and probabilities_2D[0][1] >= confidence_level and probabilities_2D_ryan[0][1] >= confidence_level:\n",
    "        all_positives_and.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate TP, FP, TN, FN and output metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find true positives\n",
    "def find_true_positives(positives, model_name):\n",
    "    true_positives = []\n",
    "    for i in positives:\n",
    "        if i in clips_w_guns:\n",
    "            true_positives.append(i)\n",
    "            create_wav_file(audio[i: i+44100], model_name + \"_true_positive_\" + str(i))\n",
    "            #create_wav_file(normalize(audio[i: i+44100]), model_name + \"_true_positive_\" + str(i))\n",
    "        \n",
    "        elif forgiving and not sliding_half and not sliding_one:\n",
    "            for j in clips_w_guns:\n",
    "                if i == j + 44100:\n",
    "                    #if this is the clip right after one labeled as having a gunshot, I'm gonna say that's still a\n",
    "                    # true positive, because odds are its a weird split\n",
    "                    if i not in true_positives:\n",
    "                        true_positives.append(i)\n",
    "                        \n",
    "        elif forgiving and sliding_one:\n",
    "            #accept the clips before and after \n",
    "            for j in clips_w_guns:\n",
    "                if i == j-22050 or i == j+22050:\n",
    "                    if i not in true_positives:\n",
    "                        true_positives.append(i)\n",
    "            \n",
    "    print(len(true_positives))\n",
    "            \n",
    "    return true_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find false positives\n",
    "def find_false_positives(positives, true_positives, model_name):\n",
    "    false_positives = []\n",
    "    for i in positives:\n",
    "        if i not in true_positives:\n",
    "            false_positives.append(i)\n",
    "            create_wav_file(audio[i: i+44100], model_name + \"_false_positive_\" + str(i))\n",
    "            #create_wav_file(normalize(audio[i: i+44100]), model_name + \"_false_positive_\" + str(i))\n",
    "            \n",
    "    return false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find false negatives\n",
    "def find_false_negatives(positives, true_positives, model_name):\n",
    "    false_negatives = []\n",
    "    for i in clips_w_guns:\n",
    "        if forgiving and sliding_one:\n",
    "            #don't call something a false negative if we caught the clip right next to it bc thats probs\n",
    "            #the same gunshot, just caught at a slightly different clip\n",
    "            if i not in positives:\n",
    "                for j in true_positives:\n",
    "                    if i != j-22050 and i != j+22050:\n",
    "                        if i not in false_negatives:\n",
    "                            false_negatives.append(i)\n",
    "                            create_wav_file(audio[i: i+44100], model_name + \"_false_negative_\" + str(i))\n",
    " \n",
    "        elif forgiving and not sliding_half and not sliding_one:\n",
    "            #don't call something a false negative if we caught the clip right next to it bc thats probs\n",
    "            #the same gunshot, just caught at a slightly different clip\n",
    "            if i not in positives:\n",
    "                for j in true_positives:\n",
    "                    if i != j-44100:\n",
    "                        if i not in false_negatives:\n",
    "                            false_negatives.append(i)\n",
    "                            create_wav_file(audio[i: i+44100], model_name + \"_false_negative_\" + str(i))\n",
    "        else:\n",
    "            if i not in positives:\n",
    "                #slice_location = i//44100\n",
    "                false_negatives.append(i)\n",
    "                create_wav_file(audio[i: i+44100], model_name + \"_false_negative_\" + str(i))\n",
    "                #create_wav_file(normalize(audio[i: i+44100]), model_name + \"_false_negative_\" + str(i))\n",
    "            \n",
    "    return false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate metrics (precison, recall, accuracy, etc)\n",
    "def find_metrics(positives, true_positives, false_positives, false_negatives, model_name):\n",
    "    total = recording_length*30\n",
    "    total_pos = len(positives)\n",
    "    total_neg = total - total_pos\n",
    "    TP = len(true_positives)\n",
    "    FP = len(false_positives)\n",
    "    FN = len(false_negatives)\n",
    "    TN = total_neg - FN \n",
    "\n",
    "    print(\"1D TFLite Model Metrics:\")\n",
    "    print(\"Total # of clips classified as gunshots: \" + str(total_pos))\n",
    "    print(\"True Positives: \" + str(TP))\n",
    "    print(\"False Positives: \" + str(FP))\n",
    "    print(\"False Negatives: \" + str(FN))\n",
    "    print(\"True Negatives: \" + str(TN))\n",
    "\n",
    "    #calculate precision, accuracy, recall, avoid dividing by 0\n",
    "    if TP + FP == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TP / (TP + FP)\n",
    "    if TP + FN == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / total\n",
    "    print(\"Precision: \" + str(precision))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "    \n",
    "    #write metrics out to a text file\n",
    "    metrics_file = open(metrics_filename, \"a\")\n",
    "    metrics_file.write( model_name + \" Model Metrics: \\n\")\n",
    "    metrics_file.write(\"Total # of clips classified as gunshots: \" + str(total_pos) + \"\\n\")\n",
    "    metrics_file.write(\"True Positives: \" + str(TP) + \"\\n\")\n",
    "    metrics_file.write(\"False Positives: \" + str(FP) + \"\\n\")\n",
    "    metrics_file.write(\"False Negatives: \" + str(FN) + \"\\n\")\n",
    "    metrics_file.write(\"True Negatives: \" + str(TN) + \"\\n\")\n",
    "    metrics_file.write(\"Precision: \" + str(precision) + \"\\n\")\n",
    "    metrics_file.write(\"Recall: \" + str(recall) + \"\\n\")\n",
    "    metrics_file.write(\"Accuracy: \" + str(accuracy) + \"\\n\\n\")\n",
    "    metrics_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "1D TFLite Model Metrics:\n",
      "Total # of clips classified as gunshots: 105\n",
      "True Positives: 51\n",
      "False Positives: 54\n",
      "False Negatives: 80\n",
      "True Negatives: 715\n",
      "Precision: 0.4857142857142857\n",
      "Recall: 0.3893129770992366\n",
      "Accuracy: 0.8511111111111112\n"
     ]
    }
   ],
   "source": [
    "false_positives_1D = []\n",
    "true_positives_1D = []\n",
    "false_negatives_1D = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_1D = find_true_positives(positives_1D, model_name_1D)\n",
    "#figure out all false positives\n",
    "false_positives_1D = find_false_positives(positives_1D, true_positives_1D, model_name_1D) \n",
    "#figure out all false negatives\n",
    "false_negatives_1D = find_false_negatives(positives_1D, true_positives_1D, model_name_1D)\n",
    "\n",
    "find_metrics(positives_1D, true_positives_1D, false_positives_1D, false_negatives_1D, model_name_1D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "1D TFLite Model Metrics:\n",
      "Total # of clips classified as gunshots: 139\n",
      "True Positives: 76\n",
      "False Positives: 63\n",
      "False Negatives: 78\n",
      "True Negatives: 683\n",
      "Precision: 0.5467625899280576\n",
      "Recall: 0.4935064935064935\n",
      "Accuracy: 0.8433333333333334\n"
     ]
    }
   ],
   "source": [
    "false_positives_2D = []\n",
    "true_positives_2D = []\n",
    "false_negatives_2D = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_2D = find_true_positives(positives_2D, model_name_2D)\n",
    "#figure out all false positives\n",
    "false_positives_2D = find_false_positives(positives_2D, true_positives_2D, model_name_2D) \n",
    "#figure out all false negatives\n",
    "false_negatives_2D = find_false_negatives(positives_2D, true_positives_2D, model_name_2D)\n",
    "\n",
    "find_metrics(positives_2D, true_positives_2D, false_positives_2D, false_negatives_2D, model_name_2D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ryan's 2D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "1D TFLite Model Metrics:\n",
      "Total # of clips classified as gunshots: 138\n",
      "True Positives: 67\n",
      "False Positives: 71\n",
      "False Negatives: 75\n",
      "True Negatives: 687\n",
      "Precision: 0.4855072463768116\n",
      "Recall: 0.47183098591549294\n",
      "Accuracy: 0.8377777777777777\n"
     ]
    }
   ],
   "source": [
    "false_positives_2D_ryan = []\n",
    "true_positives_2D_ryan = []\n",
    "false_negatives_2D_ryan = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_2D_ryan = find_true_positives(positives_2D_ryan, model_name_ryan)\n",
    "#figure out all false positives\n",
    "false_positives_2D_ryan = find_false_positives(positives_2D_ryan, true_positives_2D_ryan, model_name_ryan) \n",
    "#figure out all false negatives\n",
    "false_negatives_2D_ryan = find_false_negatives(positives_2D_ryan, true_positives_2D_ryan, model_name_ryan)\n",
    "\n",
    "find_metrics(positives_2D_ryan, true_positives_2D_ryan, false_positives_2D_ryan, false_negatives_2D_ryan, model_name_ryan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All models - or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "1D TFLite Model Metrics:\n",
      "Total # of clips classified as gunshots: 190\n",
      "True Positives: 98\n",
      "False Positives: 92\n",
      "False Negatives: 56\n",
      "True Negatives: 654\n",
      "Precision: 0.5157894736842106\n",
      "Recall: 0.6363636363636364\n",
      "Accuracy: 0.8355555555555556\n"
     ]
    }
   ],
   "source": [
    "false_positives_all = []\n",
    "true_positives_all = []\n",
    "false_negatives_all = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_all = find_true_positives(all_positives, \"All (or)\")\n",
    "#figure out all false positives\n",
    "false_positives_all = find_false_positives(all_positives, true_positives_all, \"All (or)\") \n",
    "#figure out all false negatives\n",
    "false_negatives_all = find_false_negatives(all_positives, true_positives_all, \"All (or)\")\n",
    "\n",
    "find_metrics(all_positives, true_positives_all, false_positives_all, false_negatives_all, \"All (or)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All models - and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "1D TFLite Model Metrics:\n",
      "Total # of clips classified as gunshots: 67\n",
      "True Positives: 31\n",
      "False Positives: 36\n",
      "False Negatives: 100\n",
      "True Negatives: 733\n",
      "Precision: 0.4626865671641791\n",
      "Recall: 0.2366412213740458\n",
      "Accuracy: 0.8488888888888889\n"
     ]
    }
   ],
   "source": [
    "false_positives_all_and = []\n",
    "true_positives_all_and = []\n",
    "false_negatives_all_and = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_all_and = find_true_positives(all_positives_and, \"All (and)\")\n",
    "#figure out all false positives\n",
    "false_positives_all_and = find_false_positives(all_positives_and, true_positives_all_and, \"All (and)\") \n",
    "#figure out all false negatives\n",
    "false_negatives_all_and = find_false_negatives(all_positives_and, true_positives_all_and, \"All (and)\")\n",
    "\n",
    "find_metrics(all_positives_and, true_positives_all_and, false_positives_all_and, false_negatives_all_and, \"All (and)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#find gunshot clips that all models classified correctly (TP for all models)\\nall_classified_TPs = []\\nfor i in clips_w_guns:\\n    if i in true_positives_1D and i in true_positives_2D and i in true_positives_2D_image and i in true_positives_1D_original:\\n        all_classified_TPs.append(i)\\n        \\nprint(\"There were \" + str(len(all_classified_TPs)) + \" gunshot clips that all models classified correctly:\")\\nprint(all_classified_TPs)\\n        \\n#find gunshot clips that all models classified incorrectly (FN for all models)\\nall_classified_FNs = []\\nfor i in clips_w_guns:\\n    if i in false_negatives_1D and i in false_negatives_2D and i in false_negatives_2D_image and i in false_negatives_1D_original:\\n        all_classified_FNs.append(i)\\n        \\nprint(\"There were \" + str(len(all_classified_FNs)) + \" gunshot clips that all models classified incorrectly:\")\\nprint(all_classified_FNs)\\n'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#find gunshot clips that all models classified correctly (TP for all models)\n",
    "all_classified_TPs = []\n",
    "for i in clips_w_guns:\n",
    "    if i in true_positives_1D and i in true_positives_2D and i in true_positives_2D_image and i in true_positives_1D_original:\n",
    "        all_classified_TPs.append(i)\n",
    "        \n",
    "print(\"There were \" + str(len(all_classified_TPs)) + \" gunshot clips that all models classified correctly:\")\n",
    "print(all_classified_TPs)\n",
    "        \n",
    "#find gunshot clips that all models classified incorrectly (FN for all models)\n",
    "all_classified_FNs = []\n",
    "for i in clips_w_guns:\n",
    "    if i in false_negatives_1D and i in false_negatives_2D and i in false_negatives_2D_image and i in false_negatives_1D_original:\n",
    "        all_classified_FNs.append(i)\n",
    "        \n",
    "print(\"There were \" + str(len(all_classified_FNs)) + \" gunshot clips that all models classified incorrectly:\")\n",
    "print(all_classified_FNs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
