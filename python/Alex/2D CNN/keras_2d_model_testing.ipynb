{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Directory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "import re\n",
    "import cv2\n",
    "import six\n",
    "from array import array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers, backend as K\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIRECTORY = \"/home/alexm/Datasets/\"\n",
    "SOUND_DATA_DIRECTORY = BASE_DIRECTORY + \"training_gunshots/\"\n",
    "MAXIMUM_AUDIO_FRAME_INTEGER_VALUE = 2 ** 15 - 1\n",
    "SOUND_NORMALIZATION_THRESHOLD = 10 ** (-1.0 / 20)\n",
    "SAMPLE_RATE_PER_TWO_SECONDS = 44100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"...Parsing sound data...\")\n",
    "samples = []\n",
    "i = 0\n",
    "\n",
    "for file in os.listdir(SOUND_DATA_DIRECTORY):\n",
    "    if file.endswith(\".wav\") and i <= 25:\n",
    "        # Adding 2 second-long samples to the list of samples\n",
    "        sample, sample_rate = librosa.load(SOUND_DATA_DIRECTORY + file)\n",
    "            \n",
    "        if len(sample) <= SAMPLE_RATE_PER_TWO_SECONDS:\n",
    "            number_of_missing_hertz = SAMPLE_RATE_PER_TWO_SECONDS - len(sample)\n",
    "            padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "            samples.append(padded_sample)\n",
    "            \n",
    "            print(\"Added a sample...\")\n",
    "            i += 1\n",
    "                \n",
    "        else:\n",
    "            for i in range(0, sample.size - SAMPLE_RATE_PER_TWO_SECONDS, SAMPLE_RATE_PER_TWO_SECONDS):\n",
    "                sample_slice = sample[i : i + SAMPLE_RATE_PER_TWO_SECONDS]\n",
    "                samples.append(sample_slice)\n",
    "                print(\"Added a sample...\")\n",
    "                i += 1\n",
    "\n",
    "print(\"The number of samples available for training is currently \" + str(len(samples)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Augmented Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"/home/alexm/Datasets/gunshot_augmented_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == 1 else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound_data):\n",
    "    absolute_maximum_sound_datum = max(abs(i) for i in sound_data)\n",
    "    \n",
    "    # Prevents a divide by zero scenario\n",
    "    if absolute_maximum_sound_datum == 0.0:\n",
    "        absolute_maximum_sound_datum = 0.001\n",
    "    \n",
    "    normalization_factor = float(SOUND_NORMALIZATION_THRESHOLD * MAXIMUM_AUDIO_FRAME_INTEGER_VALUE) / absolute_maximum_sound_datum\n",
    "    \n",
    "    # Averages the volume out\n",
    "    r = array('f')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * normalization_factor))\n",
    "    return np.array(r, dtype = np.float32)\n",
    "\n",
    "\n",
    "def convert_to_spectrogram(data, sample_rate):\n",
    "    return np.array(librosa.feature.melspectrogram(y = data, sr = sample_rate), dtype = \"float32\")\n",
    "\n",
    "\n",
    "def power_to_db(S, ref = 1.0, amin = 1e-10, top_db = 80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        logger.debug('ParameterError: amin must be strictly positive')\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        logger.debug('Warning: power_to_db was called on complex input so phase '\n",
    "                      'information will be discarded. To suppress this warning, '\n",
    "                      'call power_to_db(np.abs(D)**2) instead.')\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            logger.debug('ParameterError: top_db must be non-negative')\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def convert_spectrogram_to_image(spectrogram):\n",
    "    plt.interactive(False)\n",
    "    \n",
    "    figure = plt.figure(figsize = [0.72, 0.72], dpi = 400)\n",
    "    plt.tight_layout(pad = 0)\n",
    "    ax = figure.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    librosa.display.specshow(power_to_db(spectrogram, ref = np.max))\n",
    "    \n",
    "    canvas = FigureCanvas(figure)\n",
    "    canvas.draw()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "\n",
    "    image = np.fromstring(figure.canvas.tostring_rgb(), dtype = \"uint8\")\n",
    "    image = image.reshape((width, height, 3))\n",
    "    image = cv2.resize(image, (192, 192))\n",
    "\n",
    "    # Cleaning up the matplotlib instance\n",
    "    plt.close()    \n",
    "    figure.clf()\n",
    "    plt.close(figure)\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    # Returns a NumPy array containing an image of a spectrogram\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(BASE_DIRECTORY + \"gunshot_2d_spectrogram_model.h5\", custom_objects = {\"auc\" : auc})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of model predictions (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in test sample WAV files\n",
    "for sample in samples:\n",
    "#     gunshot_training_sample = normalize(sample)\n",
    "    number_of_missing_hertz = 44100 - len(gunshot_training_sample)\n",
    "    gunshot_training_sample = np.array(gunshot_training_sample.tolist() + [0 for i in range(number_of_missing_hertz)], dtype = \"float32\")\n",
    "    gunshot_training_sample_spectrogram = convert_to_spectrogram(gunshot_training_sample, 22050)\n",
    "    gunshot_training_sample_spectrogram = convert_spectrogram_to_image(gunshot_training_sample_spectrogram)\n",
    "    gunshot_training_sample_spectrogram = gunshot_training_sample_spectrogram.reshape((-1, 192, 192, 3))\n",
    "    gunshot_training_sample_spectrogram = gunshot_training_sample_spectrogram.astype(\"float32\")\n",
    "    gunshot_training_sample_spectrogram /= 255\n",
    "\n",
    "    probabilities = model.predict(gunshot_training_sample_spectrogram)\n",
    "    print(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "    print(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of an individual incorrectly-labeled example (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(gunshot_training_sample, rate = 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gunshot_detection",
   "language": "python",
   "name": "gunshot_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
