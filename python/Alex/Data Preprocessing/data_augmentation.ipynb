{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Directory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "import re\n",
    "import cv2\n",
    "import six\n",
    "from array import array\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers, backend as K\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUNSHOT_FREQUENCY_THESHOLD = 0.25\n",
    "SAMPLE_RATE_PER_SECOND = 22050\n",
    "SAMPLE_RATE_PER_TWO_SECONDS = 44100\n",
    "HOP_LENGTH = 345 * 2\n",
    "MINIMUM_FREQUENCY = 20\n",
    "MAXIMUM_FREQUENCY = SAMPLE_RATE_PER_SECOND\n",
    "NUMBER_OF_MELS = 128\n",
    "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
    "BASE_DIRECTORY = \"/home/alexm/Datasets/\"\n",
    "DATA_CATEGORY = \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NumPy files as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(BASE_DIRECTORY + DATA_CATEGORY + \"_samples.npy\")\n",
    "labels = np.load(BASE_DIRECTORY + DATA_CATEGORY +  \"_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(sample):\n",
    "    start_ = int(np.random.uniform(-7000, 7000))\n",
    "    if start_ >= 0:\n",
    "        sample_time_shift = np.r_[sample[start_:], np.random.uniform(-0.001, 0.001, start_)]\n",
    "    else:\n",
    "        sample_time_shift = np.r_[np.random.uniform(-0.001, 0.001, -start_), sample[:start_]]\n",
    "    return sample_time_shift\n",
    "    \n",
    "def change_pitch(sample, sample_rate):\n",
    "    magnitude = (np.random.uniform(-0.1, 0.1))\n",
    "    sample_pitch_change = librosa.effects.pitch_shift(sample, sample_rate, magnitude)\n",
    "    return sample_pitch_change\n",
    "    \n",
    "def speed_change(sample):\n",
    "    speed_rate = np.random.uniform(0.7, 1.3)\n",
    "    sample_speed_tune = cv2.resize(sample, (1, int(len(sample) * speed_rate))).squeeze()\n",
    "    \n",
    "    if len(sample_speed_tune) < len(sample):\n",
    "        pad_len = len(sample) - len(sample_speed_tune)\n",
    "        sample_speed_tune = np.r_[np.random.uniform(-0.0001, 0.0001, int(pad_len / 2)),\n",
    "                               sample_speed_tune,\n",
    "                               np.random.uniform(-0.0001, 0.0001, int(np.ceil(pad_len / 2)))]\n",
    "    else: \n",
    "        cut_len = len(sample_speed_tune) - len(sample)\n",
    "        sample_speed_tune = sample_speed_tune[int(cut_len / 2) : int(cut_len / 2) + len(sample)]\n",
    "    return sample_speed_tune\n",
    "    \n",
    "def change_volume(sample, magnitude):\n",
    "    # 0 < x < 1 quieter; x = 1 identity; x > 1 louder\n",
    "    sample_volume_change = np.multiply(np.array([magnitude]), sample)\n",
    "    return sample_volume_change\n",
    "    \n",
    "def add_background(sample, samples, labels, label_to_avoid):\n",
    "    sample_index = np.where(samples == sample)[0][0]\n",
    "    chosen_bg_sample = samples[np.random.randint(len(samples))]\n",
    "    chosen_bg_sample_index = np.where(samples == chosen_bg_sample)[0][0]\n",
    "    while chosen_bg_sample_index == sample_index or labels[chosen_bg_sample_index] == label_to_avoid:\n",
    "        print(\"Choosing another background sample...\")\n",
    "        chosen_bg_sample = samples[np.random.randint(len(samples))]\n",
    "        chosen_bg_sample_index = np.where(samples == chosen_bg_sample)[0][0]\n",
    "    ceil = max((chosen_bg_sample.shape[0] - sample.shape[0]), 1)\n",
    "    start_ = np.random.randint(ceil)\n",
    "    bg_slice = chosen_bg_sample[start_ : start_ + sample.shape[0]]\n",
    "    if bg_slice.shape[0] < sample.shape[0]:\n",
    "        pad_len = sample.shape[0] - bg_slice.shape[0]\n",
    "        bg_slice = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)), bg_slice, np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    sample_with_bg = sample * np.random.uniform(0.8, 1.2) + bg_slice * np.random.uniform(0, 0.5)\n",
    "    return sample_with_bg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting data (i.e. time shifting, speed changing, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)\n",
    "number_of_augmentations = 5\n",
    "augmented_samples = np.zeros((samples.shape[0] * (number_of_augmentations + 1), SAMPLE_RATE_PER_TWO_SECONDS))\n",
    "augmented_labels = []\n",
    "j = 0\n",
    "\n",
    "for i in range (0, len(augmented_samples), (number_of_augmentations + 1)):\n",
    "    augmented_samples[i,:] = samples[j,:]\n",
    "    augmented_samples[i + 1,:] = time_shift(samples[j,:])\n",
    "    augmented_samples[i + 2,:] = change_pitch(samples[j,:], SAMPLE_RATE_PER_SECOND)\n",
    "    augmented_samples[i + 3,:] = speed_change(samples[j,:])\n",
    "    augmented_samples[i + 4,:] = change_volume(samples[j,:], np.random.uniform())\n",
    "    \n",
    "    if labels[j] == \"gun_shot\":\n",
    "        augmented_samples[i + 5,:] = add_background(samples[j,:], samples, labels, \"\") \n",
    "    else:\n",
    "        augmented_samples[i + 5,:] = add_background(samples[j,:], samples, labels, \"gun_shot\")\n",
    "    \n",
    "    # Accounts for multiplicably increasing the number of samples through augmentations\n",
    "    for sample_version in range(number_of_augmentations + 1):\n",
    "        augmented_labels.append(labels[j])\n",
    "    \n",
    "    print(\"Finished augmenting \" + DATA_CATEGORY + \" sample #\" + str(j + 1))\n",
    "    j += 1\n",
    "\n",
    "samples = augmented_samples\n",
    "labels = augmented_labels\n",
    "\n",
    "print(\"The number of samples available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving augmented NumPy arrays as NumPy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(BASE_DIRECTORY + \"augmented_\" + DATA_CATEGORY + \"_samples.npy\", samples)\n",
    "np.save(BASE_DIRECTORY + \"augmented_\" + DATA_CATEGORY + \"_labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of the sample and label data's shape (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of samples array:\", samples.shape)\n",
    "print(\"Length of labels list:\", len(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gunshot_detection",
   "language": "python",
   "name": "gunshot_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
