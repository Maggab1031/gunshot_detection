{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import csv\n",
    "import IPython.display as ipd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "import IPython\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(wav):\n",
    "    start_ = int(np.random.uniform(-wav.shape[0] * 0.5, wav.shape[0] * 0.5))\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001, 0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001, 0.001, -start_), wav[:start_]]\n",
    "    return wav_time_shift\n",
    "    \n",
    "def change_pitch(wav, sample_rate):\n",
    "    magnitude = int(np.random.uniform(-10, 10))\n",
    "    wav_pitch_change = librosa.effects.pitch_shift(wav, sample_rate, magnitude)\n",
    "    return wav_pitch_change\n",
    "    \n",
    "def speed_change(wav):\n",
    "    speed_rate = np.random.uniform(0.7, 1.3)\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "    \n",
    "    if len(wav_speed_tune) < len(wav):\n",
    "        pad_len = len(wav) - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    else: \n",
    "        cut_len = len(wav_speed_tune) - len(wav)\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len / 2) : int(cut_len / 2) + len(wav)]\n",
    "    return wav_speed_tune\n",
    "    \n",
    "def change_volume(wav, magnitude):\n",
    "    # 0 < x < 1 quieter; x = 1 identity; x > 1 louder\n",
    "    wav_volume_change = np.multiply(np.array([magnitude]), wav)\n",
    "    return wav_volume_change\n",
    "    \n",
    "def add_background(wav, file, data_directory, label_to_avoid):\n",
    "    label_csv = data_directory + \"train.csv\"\n",
    "    sound_directory = data_directory + \"Train/\"\n",
    "    sound_types = pd.read_csv(label_csv)\n",
    "    bg_files = os.listdir(sound_directory)\n",
    "    bg_files.remove(file)\n",
    "    chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "    jndex = int(chosen_bg_file.split('.')[0])\n",
    "    while sound_types.loc[sound_types[\"ID\"] == jndex, \"Class\"].values[0] == label_to_avoid:\n",
    "        chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "        jndex = int(chosen_bg_file.split('.')[0])\n",
    "    bg, sr = librosa.load(sound_directory + chosen_bg_file)\n",
    "    ceil = max((bg.shape[0] - wav.shape[0]), 1)\n",
    "    start_ = np.random.randint(ceil)\n",
    "    bg_slice = bg[start_ : start_ + wav.shape[0]]\n",
    "    if bg_slice.shape[0] < wav.shape[0]:\n",
    "        pad_len = wav.shape[0] - bg_slice.shape[0]\n",
    "        bg_slice = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)), bg_slice, np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    wav_with_bg = wav * np.random.uniform(0.8, 1.2) + bg_slice * np.random.uniform(0, 0.5)\n",
    "    return wav_with_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spectrogram(y,sr):\n",
    "    return np.array(librosa.feature.melspectrogram(y=a, sr=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"/home/gamagee/workspace/gunshot_detection/REU_Data/REU_Samples_and_Labels/\"\n",
    "label_csv = data_directory + \"labels.csv\"\n",
    "sample_directory = data_directory + \"Samples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "d = {}\n",
    "with open(label_csv,\"r\") as lblcsv:\n",
    "    c = list(csv.reader(lblcsv))\n",
    "    header = c[0]\n",
    "    for row in c[1:]:\n",
    "        e = {}\n",
    "        e[\"label\"] = row[1]\n",
    "        e[\"source\"] = row[2]\n",
    "        d[row[0]+\".wav\"] = e\n",
    "        if row[1] not in s:\n",
    "            s.append(row[1])\n",
    "print(d)\n",
    "print(len(s))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##preprocessing data\n",
    "\n",
    "for file in os.listdir(sample_directory):\n",
    "    y,sr = librosa.load(sample_directory+file)\n",
    "    n = make_spectrogram(y,sr)\n",
    "    print(n.shape)\n",
    "\n",
    "exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "#Loading previous model\n",
    "#model = load_model(base_dir + \"gunshot_sound_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\"\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-921c84dea0c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "#Model Parameters\n",
    "drop_out_rate = 0.1\n",
    "learning_rate = 0.001\n",
    "number_of_epochs = 100\n",
    "number_of_classes = 2\n",
    "batch_size = 32\n",
    "optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "input_tensor = Input(shape=input_shape)\n",
    "metrics = [auc, \"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cc6484ec4c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Model Architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_out_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "#Model Architecture\n",
    "x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(16)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuring model properties\n",
    "model_filename = base_dir + \"gunshot_sound_model.pkl\"\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor='val_acc',\n",
    "                  patience=10,\n",
    "                  verbose=1,\n",
    "                  mode='auto'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='auto'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional debugging of the model's architecture\n",
    "model.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training & caching the model\n",
    "History = model.fit(train_wav, train_label, \n",
    "          validation_data=[test_wav, test_label],\n",
    "          epochs=number_of_epochs,\n",
    "          callbacks=model_callbacks,\n",
    "          verbose=1,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True)\n",
    "model.save(base_dir + \"gunshot_sound_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
