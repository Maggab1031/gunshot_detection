{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, GlobalAveragePooling1D, MaxPooling1D, Dense, Dropout, Activation, Flatten\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import csv\n",
    "import IPython.display as ipd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "import IPython\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "# In[8]:\n",
    "\n",
    "print(get_available_gpus())\n",
    "\n",
    "def time_shift(wav):\n",
    "    start_ = int(np.random.uniform(-wav.shape[0] * 0.5, wav.shape[0] * 0.5))\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001, 0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001, 0.001, -start_), wav[:start_]]\n",
    "    return wav_time_shift\n",
    "\n",
    "def change_pitch(wav, sample_rate):\n",
    "    magnitude = int(np.random.uniform(-10, 10))\n",
    "    wav_pitch_change = librosa.effects.pitch_shift(wav, sample_rate, magnitude)\n",
    "    return wav_pitch_change\n",
    "\n",
    "def speed_change(wav):\n",
    "    speed_rate = np.random.uniform(0.7, 1.3)\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "\n",
    "    if len(wav_speed_tune) < len(wav):\n",
    "        pad_len = len(wav) - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    else:\n",
    "        cut_len = len(wav_speed_tune) - len(wav)\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len / 2) : int(cut_len / 2) + len(wav)]\n",
    "    return wav_speed_tune\n",
    "\n",
    "def change_volume(wav, magnitude):\n",
    "    # 0 < x < 1 quieter; x = 1 identity; x > 1 louder\n",
    "    wav_volume_change = np.multiply(np.array([magnitude]), wav)\n",
    "    return wav_volume_change\n",
    "\n",
    "def add_background(wav, file, data_directory, label_to_avoid):\n",
    "    label_csv = data_directory + \"train.csv\"\n",
    "    sound_directory = data_directory + \"Train/\"\n",
    "    sound_types = pd.read_csv(label_csv)\n",
    "    bg_files = os.listdir(sound_directory)\n",
    "    bg_files.remove(file)\n",
    "    chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "    jndex = int(chosen_bg_file.split('.')[0])\n",
    "    while sound_types.loc[sound_types[\"ID\"] == jndex, \"Class\"].values[0] == label_to_avoid:\n",
    "        chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "        jndex = int(chosen_bg_file.split('.')[0])\n",
    "    bg, sr = librosa.load(sound_directory + chosen_bg_file)\n",
    "    ceil = max((bg.shape[0] - wav.shape[0]), 1)\n",
    "    start_ = np.random.randint(ceil)\n",
    "    bg_slice = bg[start_ : start_ + wav.shape[0]]\n",
    "    if bg_slice.shape[0] < wav.shape[0]:\n",
    "        pad_len = wav.shape[0] - bg_slice.shape[0]\n",
    "        bg_slice = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)), bg_slice, np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    wav_with_bg = wav * np.random.uniform(0.8, 1.2) + bg_slice * np.random.uniform(0, 0.5)\n",
    "    return wav_with_bg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_spectrogram(y):\n",
    "    y = np.array(y)\n",
    "    print(type(y))\n",
    "    print(y.dtype)\n",
    "    return np.array(librosa.feature.melspectrogram(y=y, sr=22050))\n",
    "\n",
    "\n",
    "def get_categories():\n",
    "    s = []\n",
    "    d = {}\n",
    "    with open(label_csv,\"r\") as lblcsv:\n",
    "        c = list(csv.reader(lblcsv))\n",
    "        header = c[0]\n",
    "        for row in c[1:]:\n",
    "            e = {}\n",
    "            e[\"label\"] = row[1]\n",
    "            e[\"source\"] = row[2]\n",
    "            d[row[0]+\".wav\"] = e\n",
    "            if row[1] not in s:\n",
    "                s.append(row[1])\n",
    "    return s,d\n",
    "\n",
    "\n",
    "#ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\"\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_available_gpus())\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "data_directory = \"/home/gamagee/workspace/gunshot_detection/REU_Data/REU_Samples_and_Labels/\"\n",
    "label_csv = data_directory + \"labels.csv\"\n",
    "sample_directory = data_directory + \"Samples/\"\n",
    "base_dir = \"/home/gamagee/workspace/gunshot_detection/REU_Data/\"\n",
    "sample_path = base_dir+\"gabe_sample.npy\"\n",
    "label_path = base_dir+\"gabe_label.npy\"\n",
    "samples = np.load(sample_path)\n",
    "labels = np.load(label_path)\n",
    "samples.reshape(-1,128,87,1)\n",
    "sample_rate_per_two_seconds = 44100\n",
    "number_of_classes = 2\n",
    "sr = 22050\n",
    "input_shape = (128, 87, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]\n",
    "\n",
    "\n",
    "def model(train_wav, train_label, test_label, test_wav, name,verbose=1,drop_out_rate = 0.1,learning_rate = 0.001,number_of_epochs = 100,batch_size = 64,filter_size = (3,3),maxpool_size = (3,3),activation = \"relu\"):\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    x = Input(shape=input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    #Model Architecture\n",
    "    x = layers.Conv2D(16, filter_size, activation=activation, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, filter_size, activation=activation, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, filter_size, activation=activation, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, filter_size, activation=activation, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "    x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation=activation)(x)\n",
    "    x = layers.Dense(1028, activation=activation)(x)\n",
    "    output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)\n",
    "\n",
    "    #Configuring model properties\n",
    "    model_filename = base_dir + \"gunshot_sound_model_spectrograph_\"+name+\".pkl\"\n",
    "\n",
    "    model_callbacks = [\n",
    "        EarlyStopping(monitor='val_acc',\n",
    "                      patience=15,\n",
    "                      verbose=1,\n",
    "                      mode='max'),\n",
    "\n",
    "        ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='max'),\n",
    "    ]\n",
    "    #Optional debugging of the model's architecture\n",
    "    model.summary()\n",
    "\n",
    "    test_wav = test_wav.reshape(-1,128,87,1)\n",
    "    train_wav = train_wav.reshape(-1,128, 87, 1)\n",
    "\n",
    "    #Training & caching the model\n",
    "    History = model.fit(train_wav, train_label,\n",
    "              validation_data=[test_wav, test_label],\n",
    "              epochs=number_of_epochs,\n",
    "              callbacks=model_callbacks,\n",
    "              verbose=verbose,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=True)\n",
    "    model.save(base_dir + \"gunshot_sound_model_spectrograph_\"+name+\".h5\")\n",
    "    return model.evaluate(test_wav, test_label, batch_size=batch_size)\n",
    "\n",
    "drop_out_rates = 0.1,0.05,0.01,0.25\n",
    "learning_rates = 0.1,0.05,0.01\n",
    "filter_sizes = (4,4),(5,5),(6,6),(3,3)\n",
    "name = \"model\"\n",
    "print(model(train_wav, train_label, test_label, test_wav, name= name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
