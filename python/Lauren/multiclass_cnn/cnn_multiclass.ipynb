{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-class CNN\n",
    "    #0: miscellanious\n",
    "    #1: gunshot\n",
    "    #2: fireworks\n",
    "    #3: glassbreak\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile\n",
    "import re\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "labels = []\n",
    "gunshot_frequency_threshold = 0.25\n",
    "sample_rate = 22050\n",
    "sample_rate_per_two_seconds = 44100\n",
    "input_shape = (sample_rate_per_two_seconds, 1)\n",
    "base_dir = \"/Users/laurenogden/Downloads/\"\n",
    "data_dir = base_dir + \"REU_Samples_and_Labels/\"\n",
    "sound_data_dir = data_dir + \"Samples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load samples and labels\n",
    "samples = np.load(base_dir + \"gunshot_sound_samples_multiclass.npy\")\n",
    "labels = np.load(base_dir + \"gunshot_sound_labels_multiclass.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to categorical\n",
    "#reminder, this is for MULTICLASS CLASSIFICATION:\n",
    "    #0: miscellanious\n",
    "    #1: gunshot\n",
    "    #2: fireworks\n",
    "    #3: glassbreak\n",
    "\n",
    "labels = keras.utils.to_categorical(labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7135, 4)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the data\n",
    "train_wav = train_wav.reshape(-1, sample_rate_per_two_seconds, 1)\n",
    "test_wav = test_wav.reshape(-1, sample_rate_per_two_seconds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4757, 44100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_wav.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC metric\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "drop_out_rate = 0.1\n",
    "learning_rate = 0.001\n",
    "number_of_epochs = 50\n",
    "number_of_classes = 4\n",
    "batch_size = 32\n",
    "optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "input_tensor = Input(shape=input_shape)\n",
    "metrics = [auc, \"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture\n",
    "x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(16)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model properties\n",
    "\n",
    "model_filename = base_dir + \"gunshot_sound_model_multiclass.pkl\"\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor='val_acc',\n",
    "                  patience=10,\n",
    "                  verbose=1,\n",
    "                  mode='auto'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='auto'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 44100, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 44100, 16)         160       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 44100, 16)         2320      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 2756, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2756, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 2756, 32)          1568      \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 2756, 32)          3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 689, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 689, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 689, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 689, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 172, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 172, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 172, 256)          24832     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 172, 256)          196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1028)              66820     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 4116      \n",
      "=================================================================\n",
      "Total params: 322,440\n",
      "Trainable params: 322,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4757 samples, validate on 2378 samples\n",
      "Epoch 1/50\n",
      "1536/4757 [========>.....................] - ETA: 2:38 - loss: 0.3930 - auc: 0.8082 - acc: 0.8455"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ef0233fb2405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           shuffle=True)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"gunshot_sound_model_multiclass.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TRAIN IT\n",
    "History = model.fit(train_wav, train_label, \n",
    "          validation_data=[test_wav, test_label],\n",
    "          epochs=number_of_epochs,\n",
    "          callbacks=model_callbacks,\n",
    "          verbose=1,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True)\n",
    "\n",
    "model.save(base_dir + \"gunshot_sound_model_multiclass.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
